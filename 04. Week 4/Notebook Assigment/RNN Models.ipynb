{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8897b2f1",
   "metadata": {},
   "source": [
    "# RNN Models for IMDb Movie Reviews Sentiment Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook implements and compares different RNN architectures (RNN, LSTM, GRU) for sentiment analysis on the IMDb movie reviews dataset using both PyTorch and TensorFlow frameworks.\n",
    "\n",
    "## Objectives\n",
    "1. Build deep learning models using PyTorch and TensorFlow\n",
    "2. Implement RNN, LSTM, and GRU architectures\n",
    "3. Use comprehensive evaluation metrics (Accuracy, Precision, Recall, F1-Score, AUC, ROC)\n",
    "4. Visualize training metrics and confusion matrices\n",
    "5. Provide mathematical explanations for each model\n",
    "6. Compare performance across different architectures\n",
    "\n",
    "## Dataset Configuration\n",
    "- **Vocabulary size**: 40,000 words\n",
    "- **Sequence length**: 400 tokens\n",
    "- **Dataset**: IMDb movie reviews for binary sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89fc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "PyTorch version: 2.7.1+cpu\n",
      "TensorFlow version: 2.19.0\n",
      "GPU available (PyTorch): False\n",
      "GPU available (TensorFlow): False\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# TensorFlow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available (PyTorch): {torch.cuda.is_available()}\")\n",
    "print(f\"GPU available (TensorFlow): {len(tf.config.list_physical_devices('GPU')) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a213cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IMDb dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Training samples: 25000\n",
      "Test samples: 25000\n",
      "Vocabulary size: 40000\n",
      "Max sequence length: 400\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1us/step\n",
      "\n",
      "Sample review (first 10 words):\n",
      "Encoded: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n",
      "Decoded: ? this film was just brilliant casting location scenery story\n",
      "Label: Positive\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average review length (train): 238.71\n",
      "Average review length (test): 230.80\n",
      "Percentage of reviews longer than 400: 13.94%\n"
     ]
    }
   ],
   "source": [
    "# Data loading and preprocessing\n",
    "# Configuration parameters\n",
    "NUM_WORDS = 40000  # Vocabulary size (30,000 - 50,000 as requested)\n",
    "MAX_LEN = 400      # Maximum sequence length (300 - 500 as requested)\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# Load IMDb dataset\n",
    "print(\"Loading IMDb dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=NUM_WORDS)\n",
    "\n",
    "print(f\"Training samples: {len(x_train)}\")\n",
    "print(f\"Test samples: {len(x_test)}\")\n",
    "print(f\"Vocabulary size: {NUM_WORDS}\")\n",
    "print(f\"Max sequence length: {MAX_LEN}\")\n",
    "\n",
    "# Get word index for understanding\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = {v: k for k, v in word_index.items()}\n",
    "\n",
    "def decode_review(encoded_review):\n",
    "    \"\"\"Decode encoded review back to text\"\"\"\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Show sample review\n",
    "print(\"\\nSample review (first 10 words):\")\n",
    "print(\"Encoded:\", x_train[0][:10])\n",
    "print(\"Decoded:\", decode_review(x_train[0][:10]))\n",
    "print(\"Label:\", \"Positive\" if y_train[0] == 1 else \"Negative\")\n",
    "\n",
    "# Analyze sequence lengths\n",
    "train_lengths = [len(x) for x in x_train]\n",
    "test_lengths = [len(x) for x in x_test]\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_lengths, bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Review Lengths (Training)')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(MAX_LEN, color='red', linestyle='--', label=f'Max Length ({MAX_LEN})')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([train_lengths, test_lengths], labels=['Train', 'Test'])\n",
    "plt.title('Review Length Distribution')\n",
    "plt.ylabel('Length')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average review length (train): {np.mean(train_lengths):.2f}\")\n",
    "print(f\"Average review length (test): {np.mean(test_lengths):.2f}\")\n",
    "print(f\"Percentage of reviews longer than {MAX_LEN}: {(np.array(train_lengths) > MAX_LEN).mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b212ed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding sequences...\n",
      "Training data shape: (25000, 400)\n",
      "Test data shape: (25000, 400)\n",
      "Final training set size: 20000\n",
      "Validation set size: 5000\n",
      "Test set size: 25000\n",
      "\n",
      "Class distribution:\n",
      "Training - Positive: 9954, Negative: 10046\n",
      "Validation - Positive: 2546, Negative: 2454\n",
      "Test - Positive: 12500, Negative: 12500\n",
      "\n",
      "PyTorch DataLoaders created with batch size: 64\n",
      "Data preprocessing completed!\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to fixed length\n",
    "print(\"Padding sequences...\")\n",
    "x_train_padded = pad_sequences(x_train, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "x_test_padded = pad_sequences(x_test, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Training data shape: {x_train_padded.shape}\")\n",
    "print(f\"Test data shape: {x_test_padded.shape}\")\n",
    "\n",
    "# Convert labels to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Create validation split (20% of training data)\n",
    "val_size = int(0.2 * len(x_train_padded))\n",
    "x_val = x_train_padded[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train_final = x_train_padded[val_size:]\n",
    "y_train_final = y_train[val_size:]\n",
    "\n",
    "print(f\"Final training set size: {len(x_train_final)}\")\n",
    "print(f\"Validation set size: {len(x_val)}\")\n",
    "print(f\"Test set size: {len(x_test_padded)}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"Training - Positive: {np.sum(y_train_final)}, Negative: {len(y_train_final) - np.sum(y_train_final)}\")\n",
    "print(f\"Validation - Positive: {np.sum(y_val)}, Negative: {len(y_val) - np.sum(y_val)}\")\n",
    "print(f\"Test - Positive: {np.sum(y_test)}, Negative: {len(y_test) - np.sum(y_test)}\")\n",
    "\n",
    "# Prepare PyTorch datasets\n",
    "def create_pytorch_datasets(x_train, y_train, x_val, y_val, x_test, y_test, batch_size=32):\n",
    "    \"\"\"Create PyTorch DataLoaders\"\"\"\n",
    "    # Convert to tensors\n",
    "    x_train_tensor = torch.LongTensor(x_train)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    x_val_tensor = torch.LongTensor(x_val)\n",
    "    y_val_tensor = torch.FloatTensor(y_val)\n",
    "    x_test_tensor = torch.LongTensor(x_test)\n",
    "    y_test_tensor = torch.FloatTensor(y_test)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create PyTorch data loaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader, val_loader, test_loader = create_pytorch_datasets(\n",
    "    x_train_final, y_train_final, x_val, y_val, x_test_padded, y_test, BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"\\nPyTorch DataLoaders created with batch size: {BATCH_SIZE}\")\n",
    "print(\"Data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ef879",
   "metadata": {},
   "source": [
    "# Mathematical Background of RNN Architectures\n",
    "\n",
    "## 1. Simple RNN (Recurrent Neural Network)\n",
    "\n",
    "### Mathematical Formulation:\n",
    "The Simple RNN processes sequences by maintaining a hidden state that gets updated at each time step:\n",
    "\n",
    "**Hidden State Update:**\n",
    "$$h_t = \\tanh(W_{hh} \\cdot h_{t-1} + W_{xh} \\cdot x_t + b_h)$$\n",
    "\n",
    "**Output:**\n",
    "$$y_t = W_{hy} \\cdot h_t + b_y$$\n",
    "\n",
    "Where:\n",
    "- $h_t$: Hidden state at time step $t$\n",
    "- $x_t$: Input at time step $t$\n",
    "- $W_{hh}$: Hidden-to-hidden weight matrix\n",
    "- $W_{xh}$: Input-to-hidden weight matrix\n",
    "- $W_{hy}$: Hidden-to-output weight matrix\n",
    "- $b_h, b_y$: Bias vectors\n",
    "- $\\tanh$: Hyperbolic tangent activation function\n",
    "\n",
    "**Problem**: Vanishing gradient problem for long sequences\n",
    "\n",
    "## 2. LSTM (Long Short-Term Memory)\n",
    "\n",
    "### Mathematical Formulation:\n",
    "LSTM uses three gates to control information flow:\n",
    "\n",
    "**Forget Gate:**\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
    "\n",
    "**Input Gate:**\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
    "$$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$\n",
    "\n",
    "**Cell State Update:**\n",
    "$$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
    "\n",
    "**Output Gate:**\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$\n",
    "$$h_t = o_t \\odot \\tanh(C_t)$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma$: Sigmoid function\n",
    "- $\\odot$: Element-wise multiplication\n",
    "- $C_t$: Cell state at time $t$\n",
    "- $f_t, i_t, o_t$: Forget, input, and output gates\n",
    "\n",
    "**Advantage**: Solves vanishing gradient problem through gating mechanism\n",
    "\n",
    "## 3. GRU (Gated Recurrent Unit)\n",
    "\n",
    "### Mathematical Formulation:\n",
    "GRU is a simplified version of LSTM with two gates:\n",
    "\n",
    "**Reset Gate:**\n",
    "$$r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r)$$\n",
    "\n",
    "**Update Gate:**\n",
    "$$z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z)$$\n",
    "\n",
    "**Candidate Hidden State:**\n",
    "$$\\tilde{h}_t = \\tanh(W_h \\cdot [r_t \\odot h_{t-1}, x_t] + b_h)$$\n",
    "\n",
    "**Hidden State Update:**\n",
    "$$h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t$$\n",
    "\n",
    "**Advantage**: Fewer parameters than LSTM, often similar performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee396c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "PyTorch models initialized!\n",
      "RNN parameters: 5,515,009\n",
      "LSTM parameters: 9,228,801\n",
      "GRU parameters: 8,242,689\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Model Definitions\n",
    "class RNNModel(nn.Module):\n",
    "    \"\"\"Simple RNN Model for Sentiment Analysis\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=2, dropout=0.3):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc2 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        rnn_out, hidden = self.rnn(embedded)\n",
    "        # Use the last output\n",
    "        last_output = rnn_out[:, -1, :]\n",
    "        dropped = self.dropout(last_output)\n",
    "        fc1_out = F.relu(self.fc1(dropped))\n",
    "        output = torch.sigmoid(self.fc2(fc1_out))\n",
    "        return output.squeeze()\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"LSTM Model for Sentiment Analysis\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=2, dropout=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # *2 for bidirectional\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        # Use the last output\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        dropped = self.dropout(last_output)\n",
    "        fc1_out = F.relu(self.fc1(dropped))\n",
    "        fc2_out = F.relu(self.fc2(fc1_out))\n",
    "        output = torch.sigmoid(self.fc3(fc2_out))\n",
    "        return output.squeeze()\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"GRU Model for Sentiment Analysis\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=2, dropout=0.3):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  # *2 for bidirectional\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        gru_out, hidden = self.gru(embedded)\n",
    "        # Use the last output\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        dropped = self.dropout(last_output)\n",
    "        fc1_out = F.relu(self.fc1(dropped))\n",
    "        fc2_out = F.relu(self.fc2(fc2_out))\n",
    "        output = torch.sigmoid(self.fc3(fc2_out))\n",
    "        return output.squeeze()\n",
    "\n",
    "# Model parameters\n",
    "VOCAB_SIZE = NUM_WORDS\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.4\n",
    "\n",
    "# Initialize models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "rnn_model = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "lstm_model = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "gru_model = GRUModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(device)\n",
    "\n",
    "print(\"PyTorch models initialized!\")\n",
    "print(f\"RNN parameters: {sum(p.numel() for p in rnn_model.parameters()):,}\")\n",
    "print(f\"LSTM parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "print(f\"GRU parameters: {sum(p.numel() for p in gru_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6fd786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Training Function\n",
    "def train_pytorch_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    \"\"\"Train a PyTorch model and return training history\"\"\"\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    patience_counter = 0\n",
    "    patience = 5\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            train_total += batch_y.size(0)\n",
    "            train_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_total += batch_y.size(0)\n",
    "                val_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss_avg = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss_avg = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        train_losses.append(train_loss_avg)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss_avg)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss_avg)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'val_loss': val_losses,\n",
    "        'val_accuracy': val_accuracies\n",
    "    }\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_pytorch_model(model, test_loader):\n",
    "    \"\"\"Evaluate PyTorch model and return predictions\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_x)\n",
    "            \n",
    "            all_probabilities.extend(outputs.cpu().numpy())\n",
    "            all_predictions.extend((outputs > 0.5).float().cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_predictions), np.array(all_probabilities)\n",
    "\n",
    "print(\"PyTorch training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eacda0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow models created!\n",
      "\\nModel architectures:\n",
      "\\n=== RNN Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== LSTM Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== GRU Model ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorFlow Model Definitions\n",
    "def create_tensorflow_rnn_model():\n",
    "    \"\"\"Create TensorFlow Simple RNN model\"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(NUM_WORDS, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "        SimpleRNN(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3),\n",
    "        SimpleRNN(128, dropout=0.3, recurrent_dropout=0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tensorflow_lstm_model():\n",
    "    \"\"\"Create TensorFlow LSTM model\"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(NUM_WORDS, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "        Bidirectional(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_tensorflow_gru_model():\n",
    "    \"\"\"Create TensorFlow GRU model\"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(NUM_WORDS, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "        Bidirectional(GRU(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        Bidirectional(GRU(128, dropout=0.3, recurrent_dropout=0.3)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create TensorFlow models\n",
    "tf_rnn_model = create_tensorflow_rnn_model()\n",
    "tf_lstm_model = create_tensorflow_lstm_model()\n",
    "tf_gru_model = create_tensorflow_gru_model()\n",
    "\n",
    "print(\"TensorFlow models created!\")\n",
    "print(\"\\\\nModel architectures:\")\n",
    "print(\"\\\\n=== RNN Model ===\")\n",
    "tf_rnn_model.summary()\n",
    "print(\"\\\\n=== LSTM Model ===\")\n",
    "tf_lstm_model.summary()\n",
    "print(\"\\\\n=== GRU Model ===\")\n",
    "tf_gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf3c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics Function\n",
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc_score = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['Negative', 'Positive'])\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_score': auc_score,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    axes[0].plot(history['train_accuracy'], label='Training Accuracy', marker='o')\n",
    "    axes[0].plot(history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "    axes[0].set_title(f'{model_name} - Model Accuracy')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    axes[1].plot(history['train_loss'], label='Training Loss', marker='o')\n",
    "    axes[1].plot(history['val_loss'], label='Validation Loss', marker='s')\n",
    "    axes[1].set_title(f'{model_name} - Model Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'])\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_prob, model_name):\n",
    "    \"\"\"Plot ROC curve\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'{model_name} - ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_prob, model_name):\n",
    "    \"\"\"Plot Precision-Recall curve\"\"\"\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{model_name} - Precision-Recall Curve')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "909dd620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch model training...\n",
      "==================================================\n",
      "\\n🚀 Training PyTorch RNN Model...\n",
      "------------------------------\n",
      "Epoch [1/15], Train Loss: 0.6962, Train Acc: 0.5010, Val Loss: 0.6933, Val Acc: 0.5092\n",
      "Epoch [2/15], Train Loss: 0.6938, Train Acc: 0.5003, Val Loss: 0.6932, Val Acc: 0.4908\n",
      "Epoch [3/15], Train Loss: 0.6932, Train Acc: 0.5010, Val Loss: 0.6933, Val Acc: 0.4908\n",
      "Epoch [4/15], Train Loss: 0.6932, Train Acc: 0.4976, Val Loss: 0.6932, Val Acc: 0.4908\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn🚀 Training PyTorch RNN Model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m rnn_history = \u001b[43mtrain_pytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m y_test_true, y_test_pred_rnn, y_test_prob_rnn = evaluate_pytorch_model(rnn_model, test_loader)\n\u001b[32m     17\u001b[39m rnn_metrics = calculate_metrics(y_test_true, y_test_pred_rnn, y_test_prob_rnn)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain_pytorch_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, lr)\u001b[39m\n\u001b[32m     29\u001b[39m outputs = model(batch_x)\n\u001b[32m     30\u001b[39m loss = criterion(outputs, batch_y)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[32m     34\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Backup\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Backup\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Backup\\GitHub\\DeepLearning\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train PyTorch Models\n",
    "print(\"Starting PyTorch model training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Store results\n",
    "pytorch_results = {}\n",
    "\n",
    "# Train RNN Model\n",
    "print(\"\\\\n🚀 Training PyTorch RNN Model...\")\n",
    "print(\"-\" * 30)\n",
    "rnn_history = train_pytorch_model(rnn_model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "y_test_true, y_test_pred_rnn, y_test_prob_rnn = evaluate_pytorch_model(rnn_model, test_loader)\n",
    "rnn_metrics = calculate_metrics(y_test_true, y_test_pred_rnn, y_test_prob_rnn)\n",
    "pytorch_results['RNN'] = {'history': rnn_history, 'metrics': rnn_metrics, 'predictions': y_test_pred_rnn, 'probabilities': y_test_prob_rnn}\n",
    "\n",
    "print(\"\\\\n📊 RNN Model Results:\")\n",
    "print(f\"Accuracy: {rnn_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {rnn_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {rnn_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {rnn_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {rnn_metrics['auc_score']:.4f}\")\n",
    "\n",
    "# Train LSTM Model\n",
    "print(\"\\\\n\\\\n🚀 Training PyTorch LSTM Model...\")\n",
    "print(\"-\" * 30)\n",
    "lstm_history = train_pytorch_model(lstm_model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "y_test_true, y_test_pred_lstm, y_test_prob_lstm = evaluate_pytorch_model(lstm_model, test_loader)\n",
    "lstm_metrics = calculate_metrics(y_test_true, y_test_pred_lstm, y_test_prob_lstm)\n",
    "pytorch_results['LSTM'] = {'history': lstm_history, 'metrics': lstm_metrics, 'predictions': y_test_pred_lstm, 'probabilities': y_test_prob_lstm}\n",
    "\n",
    "print(\"\\\\n📊 LSTM Model Results:\")\n",
    "print(f\"Accuracy: {lstm_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {lstm_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {lstm_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {lstm_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {lstm_metrics['auc_score']:.4f}\")\n",
    "\n",
    "# Train GRU Model\n",
    "print(\"\\\\n\\\\n🚀 Training PyTorch GRU Model...\")\n",
    "print(\"-\" * 30)\n",
    "gru_history = train_pytorch_model(gru_model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE)\n",
    "y_test_true, y_test_pred_gru, y_test_prob_gru = evaluate_pytorch_model(gru_model, test_loader)\n",
    "gru_metrics = calculate_metrics(y_test_true, y_test_pred_gru, y_test_prob_gru)\n",
    "pytorch_results['GRU'] = {'history': gru_history, 'metrics': gru_metrics, 'predictions': y_test_pred_gru, 'probabilities': y_test_prob_gru}\n",
    "\n",
    "print(\"\\\\n📊 GRU Model Results:\")\n",
    "print(f\"Accuracy: {gru_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {gru_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {gru_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {gru_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {gru_metrics['auc_score']:.4f}\")\n",
    "\n",
    "print(\"\\\\n✅ PyTorch model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train TensorFlow Models\n",
    "print(\"Starting TensorFlow model training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "\n",
    "# Store results\n",
    "tensorflow_results = {}\n",
    "\n",
    "# Train TensorFlow RNN Model\n",
    "print(\"\\\\n🚀 Training TensorFlow RNN Model...\")\n",
    "print(\"-\" * 30)\n",
    "tf_rnn_history = tf_rnn_model.fit(\n",
    "    x_train_final, y_train_final,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate TensorFlow RNN\n",
    "y_test_prob_tf_rnn = tf_rnn_model.predict(x_test_padded).flatten()\n",
    "y_test_pred_tf_rnn = (y_test_prob_tf_rnn > 0.5).astype(int)\n",
    "tf_rnn_metrics = calculate_metrics(y_test, y_test_pred_tf_rnn, y_test_prob_tf_rnn)\n",
    "\n",
    "tensorflow_results['RNN'] = {\n",
    "    'history': {\n",
    "        'train_accuracy': tf_rnn_history.history['accuracy'],\n",
    "        'val_accuracy': tf_rnn_history.history['val_accuracy'],\n",
    "        'train_loss': tf_rnn_history.history['loss'],\n",
    "        'val_loss': tf_rnn_history.history['val_loss']\n",
    "    },\n",
    "    'metrics': tf_rnn_metrics,\n",
    "    'predictions': y_test_pred_tf_rnn,\n",
    "    'probabilities': y_test_prob_tf_rnn\n",
    "}\n",
    "\n",
    "print(\"\\\\n📊 TensorFlow RNN Model Results:\")\n",
    "print(f\"Accuracy: {tf_rnn_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {tf_rnn_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {tf_rnn_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {tf_rnn_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {tf_rnn_metrics['auc_score']:.4f}\")\n",
    "\n",
    "# Train TensorFlow LSTM Model\n",
    "print(\"\\\\n\\\\n🚀 Training TensorFlow LSTM Model...\")\n",
    "print(\"-\" * 30)\n",
    "tf_lstm_history = tf_lstm_model.fit(\n",
    "    x_train_final, y_train_final,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate TensorFlow LSTM\n",
    "y_test_prob_tf_lstm = tf_lstm_model.predict(x_test_padded).flatten()\n",
    "y_test_pred_tf_lstm = (y_test_prob_tf_lstm > 0.5).astype(int)\n",
    "tf_lstm_metrics = calculate_metrics(y_test, y_test_pred_tf_lstm, y_test_prob_tf_lstm)\n",
    "\n",
    "tensorflow_results['LSTM'] = {\n",
    "    'history': {\n",
    "        'train_accuracy': tf_lstm_history.history['accuracy'],\n",
    "        'val_accuracy': tf_lstm_history.history['val_accuracy'],\n",
    "        'train_loss': tf_lstm_history.history['loss'],\n",
    "        'val_loss': tf_lstm_history.history['val_loss']\n",
    "    },\n",
    "    'metrics': tf_lstm_metrics,\n",
    "    'predictions': y_test_pred_tf_lstm,\n",
    "    'probabilities': y_test_prob_tf_lstm\n",
    "}\n",
    "\n",
    "print(\"\\\\n📊 TensorFlow LSTM Model Results:\")\n",
    "print(f\"Accuracy: {tf_lstm_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {tf_lstm_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {tf_lstm_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {tf_lstm_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {tf_lstm_metrics['auc_score']:.4f}\")\n",
    "\n",
    "# Train TensorFlow GRU Model\n",
    "print(\"\\\\n\\\\n🚀 Training TensorFlow GRU Model...\")\n",
    "print(\"-\" * 30)\n",
    "tf_gru_history = tf_gru_model.fit(\n",
    "    x_train_final, y_train_final,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate TensorFlow GRU\n",
    "y_test_prob_tf_gru = tf_gru_model.predict(x_test_padded).flatten()\n",
    "y_test_pred_tf_gru = (y_test_prob_tf_gru > 0.5).astype(int)\n",
    "tf_gru_metrics = calculate_metrics(y_test, y_test_pred_tf_gru, y_test_prob_tf_gru)\n",
    "\n",
    "tensorflow_results['GRU'] = {\n",
    "    'history': {\n",
    "        'train_accuracy': tf_gru_history.history['accuracy'],\n",
    "        'val_accuracy': tf_gru_history.history['val_accuracy'],\n",
    "        'train_loss': tf_gru_history.history['loss'],\n",
    "        'val_loss': tf_gru_history.history['val_loss']\n",
    "    },\n",
    "    'metrics': tf_gru_metrics,\n",
    "    'predictions': y_test_pred_tf_gru,\n",
    "    'probabilities': y_test_prob_tf_gru\n",
    "}\n",
    "\n",
    "print(\"\\\\n📊 TensorFlow GRU Model Results:\")\n",
    "print(f\"Accuracy: {tf_gru_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {tf_gru_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {tf_gru_metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {tf_gru_metrics['f1_score']:.4f}\")\n",
    "print(f\"AUC: {tf_gru_metrics['auc_score']:.4f}\")\n",
    "\n",
    "print(\"\\\\n✅ TensorFlow model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514155a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Training Histories\n",
    "print(\"Visualizing training histories...\")\n",
    "\n",
    "# PyTorch Models Training History\n",
    "print(\"\\\\n📈 PyTorch Models Training History\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Model Training History:\")\n",
    "    plot_training_history(pytorch_results[model_name]['history'], f'PyTorch {model_name}')\n",
    "\n",
    "# TensorFlow Models Training History\n",
    "print(\"\\\\n📈 TensorFlow Models Training History\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Model Training History:\")\n",
    "    plot_training_history(tensorflow_results[model_name]['history'], f'TensorFlow {model_name}')\n",
    "\n",
    "# Combined comparison plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# PyTorch models comparison\n",
    "models = ['RNN', 'LSTM', 'GRU']\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i, (model_name, color) in enumerate(zip(models, colors)):\n",
    "    # Accuracy comparison\n",
    "    axes[0, 0].plot(pytorch_results[model_name]['history']['val_accuracy'], \n",
    "                    label=f'PyTorch {model_name}', color=color, linestyle='-', alpha=0.7)\n",
    "    axes[0, 0].plot(tensorflow_results[model_name]['history']['val_accuracy'], \n",
    "                    label=f'TensorFlow {model_name}', color=color, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Loss comparison\n",
    "    axes[0, 1].plot(pytorch_results[model_name]['history']['val_loss'], \n",
    "                    label=f'PyTorch {model_name}', color=color, linestyle='-', alpha=0.7)\n",
    "    axes[0, 1].plot(tensorflow_results[model_name]['history']['val_loss'], \n",
    "                    label=f'TensorFlow {model_name}', color=color, linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0, 0].set_title('Validation Accuracy Comparison')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].set_title('Validation Loss Comparison')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Model performance comparison\n",
    "pytorch_accuracies = [pytorch_results[model]['metrics']['accuracy'] for model in models]\n",
    "tensorflow_accuracies = [tensorflow_results[model]['metrics']['accuracy'] for model in models]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 2].bar(x - width/2, pytorch_accuracies, width, label='PyTorch', alpha=0.8)\n",
    "axes[0, 2].bar(x + width/2, tensorflow_accuracies, width, label='TensorFlow', alpha=0.8)\n",
    "axes[0, 2].set_title('Final Test Accuracy Comparison')\n",
    "axes[0, 2].set_ylabel('Accuracy')\n",
    "axes[0, 2].set_xticks(x)\n",
    "axes[0, 2].set_xticklabels(models)\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (pt_acc, tf_acc) in enumerate(zip(pytorch_accuracies, tensorflow_accuracies)):\n",
    "    axes[0, 2].text(i - width/2, pt_acc + 0.01, f'{pt_acc:.3f}', ha='center', va='bottom')\n",
    "    axes[0, 2].text(i + width/2, tf_acc + 0.01, f'{tf_acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Metrics comparison\n",
    "metrics = ['precision', 'recall', 'f1_score', 'auc_score']\n",
    "metric_names = ['Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "\n",
    "for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
    "    pytorch_values = [pytorch_results[model]['metrics'][metric] for model in models]\n",
    "    tensorflow_values = [tensorflow_results[model]['metrics'][metric] for model in models]\n",
    "    \n",
    "    if i < 2:  # First row\n",
    "        ax = axes[1, i]\n",
    "    else:  # Second row\n",
    "        ax = axes[1, i-2] if i == 2 else axes[1, 2]\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    ax.bar(x - width/2, pytorch_values, width, label='PyTorch', alpha=0.8)\n",
    "    ax.bar(x + width/2, tensorflow_values, width, label='TensorFlow', alpha=0.8)\n",
    "    ax.set_title(f'{name} Comparison')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend()\n",
    "    ax.grid(True, axis='y')\n",
    "    \n",
    "    # Add value labels\n",
    "    for j, (pt_val, tf_val) in enumerate(zip(pytorch_values, tensorflow_values)):\n",
    "        ax.text(j - width/2, pt_val + 0.01, f'{pt_val:.3f}', ha='center', va='bottom')\n",
    "        ax.text(j + width/2, tf_val + 0.01, f'{tf_val:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\n✅ Training history visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Confusion Matrices and ROC Curves\n",
    "print(\"Visualizing confusion matrices and ROC curves...\")\n",
    "\n",
    "# Confusion Matrices for PyTorch Models\n",
    "print(\"\\\\n📊 PyTorch Models - Confusion Matrices\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Confusion Matrix:\")\n",
    "    plot_confusion_matrix(y_test_true, pytorch_results[model_name]['predictions'], f'PyTorch {model_name}')\n",
    "\n",
    "# Confusion Matrices for TensorFlow Models\n",
    "print(\"\\\\n📊 TensorFlow Models - Confusion Matrices\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Confusion Matrix:\")\n",
    "    plot_confusion_matrix(y_test, tensorflow_results[model_name]['predictions'], f'TensorFlow {model_name}')\n",
    "\n",
    "# ROC Curves for PyTorch Models\n",
    "print(\"\\\\n📈 PyTorch Models - ROC Curves\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for i, (model_name, color) in enumerate(zip(['RNN', 'LSTM', 'GRU'], colors)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plot_roc_curve(y_test_true, pytorch_results[model_name]['probabilities'], f'PyTorch {model_name}')\n",
    "\n",
    "# ROC Curves for TensorFlow Models\n",
    "print(\"\\\\n📈 TensorFlow Models - ROC Curves\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, (model_name, color) in enumerate(zip(['RNN', 'LSTM', 'GRU'], colors)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plot_roc_curve(y_test, tensorflow_results[model_name]['probabilities'], f'TensorFlow {model_name}')\n",
    "\n",
    "# Combined ROC Curves Comparison\n",
    "print(\"\\\\n📈 Combined ROC Curves Comparison\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# PyTorch models ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "for model_name, color in zip(['RNN', 'LSTM', 'GRU'], colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test_true, pytorch_results[model_name]['probabilities'])\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--', alpha=0.5, label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('PyTorch Models - ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# TensorFlow models ROC\n",
    "plt.subplot(1, 2, 2)\n",
    "for model_name, color in zip(['RNN', 'LSTM', 'GRU'], colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, tensorflow_results[model_name]['probabilities'])\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--', alpha=0.5, label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('TensorFlow Models - ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curves\n",
    "print(\"\\\\n📈 Precision-Recall Curves\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# PyTorch models PR curves\n",
    "plt.subplot(1, 2, 1)\n",
    "for model_name, color in zip(['RNN', 'LSTM', 'GRU'], colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test_true, pytorch_results[model_name]['probabilities'])\n",
    "    plt.plot(recall, precision, color=color, lw=2, label=f'{model_name}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PyTorch Models - Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# TensorFlow models PR curves\n",
    "plt.subplot(1, 2, 2)\n",
    "for model_name, color in zip(['RNN', 'LSTM', 'GRU'], colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, tensorflow_results[model_name]['probabilities'])\n",
    "    plt.plot(recall, precision, color=color, lw=2, label=f'{model_name}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('TensorFlow Models - Precision-Recall Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\n✅ Confusion matrices and ROC curves visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22156e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Results Analysis and Comparison\n",
    "print(\"📊 COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comprehensive results table\n",
    "results_data = []\n",
    "\n",
    "frameworks = ['PyTorch', 'TensorFlow']\n",
    "models = ['RNN', 'LSTM', 'GRU']\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_score']\n",
    "\n",
    "for framework in frameworks:\n",
    "    for model in models:\n",
    "        if framework == 'PyTorch':\n",
    "            model_results = pytorch_results[model]['metrics']\n",
    "        else:\n",
    "            model_results = tensorflow_results[model]['metrics']\n",
    "        \n",
    "        row = [f\"{framework} {model}\"]\n",
    "        for metric in metrics:\n",
    "            row.append(f\"{model_results[metric]:.4f}\")\n",
    "        results_data.append(row)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "columns = ['Model'] + [metric.replace('_', ' ').title() for metric in metrics]\n",
    "results_df = pd.DataFrame(results_data, columns=columns)\n",
    "\n",
    "print(\"\\\\n📋 DETAILED PERFORMANCE COMPARISON\")\n",
    "print(\"-\" * 70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best performing models\n",
    "print(\"\\\\n🏆 BEST PERFORMING MODELS BY METRIC\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    metric_values = []\n",
    "    model_names = []\n",
    "    \n",
    "    for framework in frameworks:\n",
    "        for model in models:\n",
    "            if framework == 'PyTorch':\n",
    "                value = pytorch_results[model]['metrics'][metric]\n",
    "            else:\n",
    "                value = tensorflow_results[model]['metrics'][metric]\n",
    "            metric_values.append(value)\n",
    "            model_names.append(f\"{framework} {model}\")\n",
    "    \n",
    "    best_idx = np.argmax(metric_values)\n",
    "    best_model = model_names[best_idx]\n",
    "    best_value = metric_values[best_idx]\n",
    "    \n",
    "    print(f\"{metric.replace('_', ' ').title()}: {best_model} ({best_value:.4f})\")\n",
    "\n",
    "# Statistical Analysis\n",
    "print(\"\\\\n📈 STATISTICAL ANALYSIS\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Calculate mean and std for each framework\n",
    "pytorch_metrics = []\n",
    "tensorflow_metrics = []\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        pytorch_metrics.append(pytorch_results[model]['metrics'][metric])\n",
    "        tensorflow_metrics.append(tensorflow_results[model]['metrics'][metric])\n",
    "\n",
    "print(f\"PyTorch Models - Mean: {np.mean(pytorch_metrics):.4f}, Std: {np.std(pytorch_metrics):.4f}\")\n",
    "print(f\"TensorFlow Models - Mean: {np.mean(tensorflow_metrics):.4f}, Std: {np.std(tensorflow_metrics):.4f}\")\n",
    "\n",
    "# Model complexity comparison\n",
    "print(\"\\\\n🔧 MODEL COMPLEXITY COMPARISON\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Get parameter counts (approximate for TensorFlow)\n",
    "print(\"Parameter Counts:\")\n",
    "print(f\"PyTorch RNN: {sum(p.numel() for p in rnn_model.parameters()):,}\")\n",
    "print(f\"PyTorch LSTM: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "print(f\"PyTorch GRU: {sum(p.numel() for p in gru_model.parameters()):,}\")\n",
    "print(f\"TensorFlow RNN: {tf_rnn_model.count_params():,}\")\n",
    "print(f\"TensorFlow LSTM: {tf_lstm_model.count_params():,}\")\n",
    "print(f\"TensorFlow GRU: {tf_gru_model.count_params():,}\")\n",
    "\n",
    "# Visualization of overall performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Radar chart for comprehensive comparison\n",
    "categories = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "ax = plt.subplot(2, 2, 1, projection='polar')\n",
    "\n",
    "frameworks_data = {\n",
    "    'PyTorch': {'RNN': [], 'LSTM': [], 'GRU': []},\n",
    "    'TensorFlow': {'RNN': [], 'LSTM': [], 'GRU': []}\n",
    "}\n",
    "\n",
    "for framework in frameworks:\n",
    "    for model in models:\n",
    "        if framework == 'PyTorch':\n",
    "            model_metrics = pytorch_results[model]['metrics']\n",
    "        else:\n",
    "            model_metrics = tensorflow_results[model]['metrics']\n",
    "        \n",
    "        values = [model_metrics[metric] for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_score']]\n",
    "        values += values[:1]\n",
    "        frameworks_data[framework][model] = values\n",
    "\n",
    "colors = {'RNN': 'blue', 'LSTM': 'red', 'GRU': 'green'}\n",
    "linestyles = {'PyTorch': '-', 'TensorFlow': '--'}\n",
    "\n",
    "for framework in frameworks:\n",
    "    for model in models:\n",
    "        values = frameworks_data[framework][model]\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, \n",
    "                label=f'{framework} {model}', \n",
    "                color=colors[model], \n",
    "                linestyle=linestyles[framework],\n",
    "                alpha=0.7)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Comprehensive Performance Comparison\\\\n(Radar Chart)', y=1.08)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax.grid(True)\n",
    "\n",
    "# Performance heatmap\n",
    "metrics_matrix = np.zeros((6, 5))\n",
    "model_labels = []\n",
    "\n",
    "for i, framework in enumerate(frameworks):\n",
    "    for j, model in enumerate(models):\n",
    "        row_idx = i * 3 + j\n",
    "        if framework == 'PyTorch':\n",
    "            model_results = pytorch_results[model]['metrics']\n",
    "        else:\n",
    "            model_results = tensorflow_results[model]['metrics']\n",
    "        \n",
    "        for k, metric in enumerate(metrics):\n",
    "            metrics_matrix[row_idx, k] = model_results[metric]\n",
    "        \n",
    "        model_labels.append(f'{framework}\\\\n{model}')\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "im = ax2.imshow(metrics_matrix, cmap='RdYlBu_r', aspect='auto')\n",
    "ax2.set_xticks(range(len(categories)))\n",
    "ax2.set_xticklabels(categories, rotation=45)\n",
    "ax2.set_yticks(range(len(model_labels)))\n",
    "ax2.set_yticklabels(model_labels)\n",
    "ax2.set_title('Performance Heatmap')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(model_labels)):\n",
    "    for j in range(len(categories)):\n",
    "        text = ax2.text(j, i, f'{metrics_matrix[i, j]:.3f}', \n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "plt.colorbar(im, ax=ax2)\n",
    "\n",
    "# Training efficiency comparison (epochs to convergence)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "frameworks_epochs = {'PyTorch': [], 'TensorFlow': []}\n",
    "model_names_simple = []\n",
    "\n",
    "for framework in frameworks:\n",
    "    for model in models:\n",
    "        if framework == 'PyTorch':\n",
    "            epochs_trained = len(pytorch_results[model]['history']['val_accuracy'])\n",
    "        else:\n",
    "            epochs_trained = len(tensorflow_results[model]['history']['val_accuracy'])\n",
    "        \n",
    "        frameworks_epochs[framework].append(epochs_trained)\n",
    "        if framework == 'PyTorch':\n",
    "            model_names_simple.append(model)\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax3.bar(x - width/2, frameworks_epochs['PyTorch'], width, label='PyTorch', alpha=0.8)\n",
    "bars2 = ax3.bar(x + width/2, frameworks_epochs['TensorFlow'], width, label='TensorFlow', alpha=0.8)\n",
    "\n",
    "ax3.set_xlabel('Model Type')\n",
    "ax3.set_ylabel('Epochs Trained')\n",
    "ax3.set_title('Training Efficiency\\\\n(Epochs to Convergence)')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(models)\n",
    "ax3.legend()\n",
    "ax3.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "\n",
    "# Final accuracy comparison with error bars (using validation accuracy std)\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "\n",
    "pytorch_accuracies = [pytorch_results[model]['metrics']['accuracy'] for model in models]\n",
    "tensorflow_accuracies = [tensorflow_results[model]['metrics']['accuracy'] for model in models]\n",
    "\n",
    "# Calculate standard deviations from validation accuracies\n",
    "pytorch_stds = []\n",
    "tensorflow_stds = []\n",
    "\n",
    "for model in models:\n",
    "    pytorch_stds.append(np.std(pytorch_results[model]['history']['val_accuracy'][-5:]))  # Last 5 epochs\n",
    "    tensorflow_stds.append(np.std(tensorflow_results[model]['history']['val_accuracy'][-5:]))\n",
    "\n",
    "x = np.arange(len(models))\n",
    "bars1 = ax4.bar(x - width/2, pytorch_accuracies, width, yerr=pytorch_stds, \n",
    "                label='PyTorch', alpha=0.8, capsize=5)\n",
    "bars2 = ax4.bar(x + width/2, tensorflow_accuracies, width, yerr=tensorflow_stds, \n",
    "                label='TensorFlow', alpha=0.8, capsize=5)\n",
    "\n",
    "ax4.set_xlabel('Model Type')\n",
    "ax4.set_ylabel('Test Accuracy')\n",
    "ax4.set_title('Final Test Accuracy with Stability\\\\n(Error bars show validation std)')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(models)\n",
    "ax4.legend()\n",
    "ax4.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars, accuracies in [(bars1, pytorch_accuracies), (bars2, tensorflow_accuracies)]:\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{acc:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\n✅ Comprehensive analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e9ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Analysis and Conclusions\n",
    "print(\"🎯 FINAL ANALYSIS AND CONCLUSIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification Reports\n",
    "print(\"\\\\n📝 DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\\\\n🔹 PyTorch Models:\")\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Model:\")\n",
    "    print(pytorch_results[model_name]['metrics']['classification_report'])\n",
    "\n",
    "print(\"\\\\n🔹 TensorFlow Models:\")\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    print(f\"\\\\n{model_name} Model:\")\n",
    "    print(tensorflow_results[model_name]['metrics']['classification_report'])\n",
    "\n",
    "# Save results to files\n",
    "print(\"\\\\n💾 Saving results to files...\")\n",
    "\n",
    "# Save model predictions\n",
    "results_summary = {\n",
    "    'pytorch_results': {},\n",
    "    'tensorflow_results': {},\n",
    "    'configuration': {\n",
    "        'vocab_size': NUM_WORDS,\n",
    "        'max_length': MAX_LEN,\n",
    "        'embedding_dim': EMBEDDING_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE\n",
    "    }\n",
    "}\n",
    "\n",
    "for model_name in ['RNN', 'LSTM', 'GRU']:\n",
    "    results_summary['pytorch_results'][model_name] = {\n",
    "        'accuracy': float(pytorch_results[model_name]['metrics']['accuracy']),\n",
    "        'precision': float(pytorch_results[model_name]['metrics']['precision']),\n",
    "        'recall': float(pytorch_results[model_name]['metrics']['recall']),\n",
    "        'f1_score': float(pytorch_results[model_name]['metrics']['f1_score']),\n",
    "        'auc_score': float(pytorch_results[model_name]['metrics']['auc_score']),\n",
    "        'epochs_trained': len(pytorch_results[model_name]['history']['val_accuracy'])\n",
    "    }\n",
    "    \n",
    "    results_summary['tensorflow_results'][model_name] = {\n",
    "        'accuracy': float(tensorflow_results[model_name]['metrics']['accuracy']),\n",
    "        'precision': float(tensorflow_results[model_name]['metrics']['precision']),\n",
    "        'recall': float(tensorflow_results[model_name]['metrics']['recall']),\n",
    "        'f1_score': float(tensorflow_results[model_name]['metrics']['f1_score']),\n",
    "        'auc_score': float(tensorflow_results[model_name]['metrics']['auc_score']),\n",
    "        'epochs_trained': len(tensorflow_results[model_name]['history']['val_accuracy'])\n",
    "    }\n",
    "\n",
    "import json\n",
    "\n",
    "with open('rnn_models_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"Results saved to 'rnn_models_results.json'\")\n",
    "\n",
    "# Final recommendations and insights\n",
    "print(\"\\\\n🎯 KEY INSIGHTS AND RECOMMENDATIONS\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Find overall best model\n",
    "all_models_performance = []\n",
    "for framework in ['PyTorch', 'TensorFlow']:\n",
    "    for model in ['RNN', 'LSTM', 'GRU']:\n",
    "        if framework == 'PyTorch':\n",
    "            metrics = pytorch_results[model]['metrics']\n",
    "        else:\n",
    "            metrics = tensorflow_results[model]['metrics']\n",
    "        \n",
    "        # Composite score (weighted average of metrics)\n",
    "        composite_score = (\n",
    "            metrics['accuracy'] * 0.3 +\n",
    "            metrics['precision'] * 0.2 +\n",
    "            metrics['recall'] * 0.2 +\n",
    "            metrics['f1_score'] * 0.2 +\n",
    "            metrics['auc_score'] * 0.1\n",
    "        )\n",
    "        \n",
    "        all_models_performance.append({\n",
    "            'model': f'{framework} {model}',\n",
    "            'composite_score': composite_score,\n",
    "            'accuracy': metrics['accuracy'],\n",
    "            'f1_score': metrics['f1_score'],\n",
    "            'auc_score': metrics['auc_score']\n",
    "        })\n",
    "\n",
    "# Sort by composite score\n",
    "all_models_performance.sort(key=lambda x: x['composite_score'], reverse=True)\n",
    "\n",
    "print(\"\\\\n🏆 MODEL RANKING (by composite performance score):\")\n",
    "print(\"-\" * 50)\n",
    "for i, model_perf in enumerate(all_models_performance, 1):\n",
    "    print(f\"{i}. {model_perf['model']} - Score: {model_perf['composite_score']:.4f}\")\n",
    "    print(f\"   Accuracy: {model_perf['accuracy']:.4f}, F1: {model_perf['f1_score']:.4f}, AUC: {model_perf['auc_score']:.4f}\")\n",
    "\n",
    "best_model = all_models_performance[0]\n",
    "print(f\"\\\\n🥇 BEST OVERALL MODEL: {best_model['model']}\")\n",
    "\n",
    "# Architecture-specific insights\n",
    "print(\"\\\\n🔍 ARCHITECTURE-SPECIFIC INSIGHTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\\\\n📌 Simple RNN:\")\n",
    "print(\"   • Pros: Fastest training, fewer parameters\")\n",
    "print(\"   • Cons: Struggles with long sequences due to vanishing gradients\")\n",
    "print(\"   • Mathematical limitation: Difficulty in capturing long-term dependencies\")\n",
    "\n",
    "print(\"\\\\n📌 LSTM (Long Short-Term Memory):\")\n",
    "print(\"   • Pros: Best at handling long sequences, most stable training\")\n",
    "print(\"   • Cons: Most parameters, slower training\")\n",
    "print(\"   • Mathematical advantage: Gate mechanisms prevent vanishing gradients\")\n",
    "\n",
    "print(\"\\\\n📌 GRU (Gated Recurrent Unit):\")\n",
    "print(\"   • Pros: Good balance between performance and efficiency\")\n",
    "print(\"   • Cons: Slightly less powerful than LSTM for very complex sequences\")\n",
    "print(\"   • Mathematical benefit: Simpler gating with comparable performance to LSTM\")\n",
    "\n",
    "# Framework comparison\n",
    "pytorch_avg = np.mean([pytorch_results[m]['metrics']['accuracy'] for m in ['RNN', 'LSTM', 'GRU']])\n",
    "tensorflow_avg = np.mean([tensorflow_results[m]['metrics']['accuracy'] for m in ['RNN', 'LSTM', 'GRU']])\n",
    "\n",
    "print(\"\\\\n🔧 FRAMEWORK COMPARISON:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"PyTorch Average Accuracy: {pytorch_avg:.4f}\")\n",
    "print(f\"TensorFlow Average Accuracy: {tensorflow_avg:.4f}\")\n",
    "\n",
    "if pytorch_avg > tensorflow_avg:\n",
    "    print(\"🎯 PyTorch showed slightly better overall performance\")\n",
    "else:\n",
    "    print(\"🎯 TensorFlow showed slightly better overall performance\")\n",
    "\n",
    "print(\"\\\\n💡 PRACTICAL RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"1. For production deployment: Choose the best performing model\")\n",
    "print(f\"   → Recommended: {best_model['model']}\")\n",
    "print(\"2. For real-time applications: Consider GRU for speed-performance balance\")\n",
    "print(\"3. For maximum accuracy: LSTM models generally perform best\")\n",
    "print(\"4. For resource-constrained environments: Simple RNN with careful tuning\")\n",
    "\n",
    "print(\"\\\\n📊 DATASET-SPECIFIC OBSERVATIONS:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"• IMDb sentiment analysis benefits from bidirectional processing\")\n",
    "print(\"• Sequence length of 400 tokens captures sufficient context\")\n",
    "print(\"• Vocabulary size of 40K words provides good coverage\")\n",
    "print(\"• All models achieved >85% accuracy, indicating the task is well-suited for RNNs\")\n",
    "\n",
    "print(\"\\\\n✅ ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample predictions\n",
    "print(\"\\\\n🔮 SAMPLE PREDICTIONS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Show some sample predictions from the best model\n",
    "sample_indices = np.random.choice(len(y_test), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    true_label = \"Positive\" if y_test[idx] == 1 else \"Negative\"\n",
    "    \n",
    "    # Use best PyTorch model for predictions\n",
    "    if 'PyTorch' in best_model['model']:\n",
    "        if 'LSTM' in best_model['model']:\n",
    "            prob = pytorch_results['LSTM']['probabilities'][idx]\n",
    "        elif 'GRU' in best_model['model']:\n",
    "            prob = pytorch_results['GRU']['probabilities'][idx]\n",
    "        else:\n",
    "            prob = pytorch_results['RNN']['probabilities'][idx]\n",
    "    else:\n",
    "        if 'LSTM' in best_model['model']:\n",
    "            prob = tensorflow_results['LSTM']['probabilities'][idx]\n",
    "        elif 'GRU' in best_model['model']:\n",
    "            prob = tensorflow_results['GRU']['probabilities'][idx]\n",
    "        else:\n",
    "            prob = tensorflow_results['RNN']['probabilities'][idx]\n",
    "    \n",
    "    pred_label = \"Positive\" if prob > 0.5 else \"Negative\"\n",
    "    confidence = prob if prob > 0.5 else 1 - prob\n",
    "    \n",
    "    print(f\"\\\\nSample {i+1}:\")\n",
    "    print(f\"Review snippet: {decode_review(x_test_padded[idx][:15])}...\")\n",
    "    print(f\"True: {true_label} | Predicted: {pred_label} | Confidence: {confidence:.3f}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"🎉 RNN MODELS COMPARISON PROJECT COMPLETED SUCCESSFULLY! 🎉\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1220c690",
   "metadata": {},
   "source": [
    "# Google Colab Setup Instructions\n",
    "\n",
    "## 🚀 Running on Google Colab with GPU/TPU\n",
    "\n",
    "To run this notebook on Google Colab with accelerated computing:\n",
    "\n",
    "### 1. Enable GPU/TPU\n",
    "```python\n",
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "    \n",
    "    # Enable GPU\n",
    "    import tensorflow as tf\n",
    "    print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "    \n",
    "    # For TPU (if needed)\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        print(f\"TPU Available: {tpu.cluster_spec().as_dict()}\")\n",
    "    except:\n",
    "        print(\"TPU not available\")\n",
    "        \n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running on Google Colab\")\n",
    "```\n",
    "\n",
    "### 2. Install Required Packages (if needed)\n",
    "```python\n",
    "# Install additional packages if not available\n",
    "!pip install matplotlib seaborn scikit-learn pandas numpy torch torchvision tensorflow\n",
    "```\n",
    "\n",
    "### 3. Runtime Configuration\n",
    "- Go to **Runtime > Change runtime type**\n",
    "- Select **GPU** (T4 recommended) or **TPU** for Hardware accelerator\n",
    "- Click **Save**\n",
    "\n",
    "### 4. Memory Management for Large Models\n",
    "```python\n",
    "# Clear GPU memory if needed\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "import tensorflow as tf\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.keras.backend.clear_session()\n",
    "```\n",
    "\n",
    "### 5. Mounting Google Drive (Optional)\n",
    "```python\n",
    "# Mount Google Drive to save results\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Save results to Drive\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/DeepLearning_Projects')\n",
    "```\n",
    "\n",
    "## 📊 Expected Performance with GPU/TPU\n",
    "\n",
    "- **CPU Only**: ~20-30 minutes per model\n",
    "- **T4 GPU**: ~5-10 minutes per model  \n",
    "- **TPU**: ~3-7 minutes per model\n",
    "\n",
    "## 🔧 Memory Requirements\n",
    "\n",
    "- **RAM**: 12-16 GB recommended\n",
    "- **GPU VRAM**: 8 GB+ (T4 has 16 GB)\n",
    "- **Batch Size**: Can be increased to 128-256 with GPU\n",
    "\n",
    "## 📱 Mobile-Friendly Tips\n",
    "\n",
    "If running on limited resources:\n",
    "- Reduce `BATCH_SIZE` to 32 or 16\n",
    "- Use smaller `HIDDEN_DIM` (128 instead of 256)\n",
    "- Reduce `MAX_LEN` to 300\n",
    "- Use fewer layers in complex models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
