{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101d40b8",
   "metadata": {},
   "source": [
    "# CNN dan MLP Models untuk SVHN Dataset\n",
    "\n",
    "## Tugas Deep Learning - Week 3\n",
    "\n",
    "**Objectives:**\n",
    "1. Membuat model Deep Learning CNN dan MLP menggunakan PyTorch dan TensorFlow\n",
    "2. Menggunakan dataset SVHN dari tensorflow_datasets dan torchvision.datasets\n",
    "3. Implementasi matriks evaluasi lengkap (Accuracy, Precision, Recall, F1-Score, AUC, ROC)\n",
    "4. Memberikan penjelasan matematika untuk setiap persamaan\n",
    "5. Mencapai akurasi minimal 75% pada training dan testing set untuk CNN\n",
    "6. Model MLP vanilla dengan akurasi bebas\n",
    "\n",
    "## Dataset: SVHN (Street View House Numbers)\n",
    "SVHN adalah dataset yang berisi gambar nomor rumah dari Google Street View. Dataset ini terdiri dari:\n",
    "- 10 kelas (digit 0-9)\n",
    "- Format gambar 32x32x3 (RGB)\n",
    "- Training set: ~73,257 gambar\n",
    "- Test set: ~26,032 gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries yang diperlukan\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import SVHN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds untuk reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"GPU available (TensorFlow):\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"GPU available (PyTorch):\", torch.cuda.is_available())\n",
    "\n",
    "# Device configuration untuk PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409f7db",
   "metadata": {},
   "source": [
    "## 1. Data Loading dan Preprocessing\n",
    "\n",
    "### Penjelasan Matematika - Normalisasi Data\n",
    "\n",
    "Normalisasi data adalah proses mengubah skala data agar berada dalam rentang tertentu. Untuk gambar RGB, kita melakukan normalisasi dengan rumus:\n",
    "\n",
    "$$X_{normalized} = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "Dimana:\n",
    "- $X$ = nilai pixel asli (0-255)\n",
    "- $\\mu$ = mean dari dataset\n",
    "- $\\sigma$ = standard deviation dari dataset\n",
    "\n",
    "Untuk dataset SVHN, nilai normalisasi umum yang digunakan:\n",
    "- Mean: [0.4377, 0.4438, 0.4728] untuk channel R, G, B\n",
    "- Std: [0.1980, 0.2010, 0.1970] untuk channel R, G, B\n",
    "\n",
    "### Data Augmentation\n",
    "\n",
    "Data augmentation adalah teknik untuk meningkatkan variasi data training dengan transformasi:\n",
    "\n",
    "$$T(x) = \\{rotation, flip, crop, brightness, contrast\\}$$\n",
    "\n",
    "Dimana $T(x)$ adalah transformasi yang diterapkan pada input $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TENSORFLOW DATA LOADING ==========\n",
    "print(\"Loading SVHN dataset with TensorFlow...\")\n",
    "\n",
    "# Load SVHN dataset menggunakan tensorflow_datasets\n",
    "(ds_train_tf, ds_test_tf), ds_info = tfds.load(\n",
    "    'svhn_cropped',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "print(f\"Dataset info: {ds_info}\")\n",
    "print(f\"Training samples: {ds_info.splits['train'].num_examples}\")\n",
    "print(f\"Testing samples: {ds_info.splits['test'].num_examples}\")\n",
    "\n",
    "# Preprocessing function untuk TensorFlow\n",
    "def preprocess_tf(image, label):\n",
    "    # Normalize pixel values ke range [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # Normalisasi dengan mean dan std ImageNet (karena SVHN belum ada standar khusus)\n",
    "    mean = tf.constant([0.485, 0.456, 0.406])\n",
    "    std = tf.constant([0.229, 0.224, 0.225])\n",
    "    image = (image - mean) / std\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Data augmentation untuk training\n",
    "def augment_tf(image, label):\n",
    "    # Random rotation\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform([], 0, 4, dtype=tf.int32))\n",
    "    # Random brightness\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # Random contrast\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "BATCH_SIZE = 128\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Training set dengan augmentation\n",
    "ds_train_tf = ds_train_tf.map(preprocess_tf, num_parallel_calls=AUTOTUNE)\n",
    "ds_train_tf = ds_train_tf.map(augment_tf, num_parallel_calls=AUTOTUNE)\n",
    "ds_train_tf = ds_train_tf.cache()\n",
    "ds_train_tf = ds_train_tf.shuffle(1000)\n",
    "ds_train_tf = ds_train_tf.batch(BATCH_SIZE)\n",
    "ds_train_tf = ds_train_tf.prefetch(AUTOTUNE)\n",
    "\n",
    "# Test set tanpa augmentation\n",
    "ds_test_tf = ds_test_tf.map(preprocess_tf, num_parallel_calls=AUTOTUNE)\n",
    "ds_test_tf = ds_test_tf.cache()\n",
    "ds_test_tf = ds_test_tf.batch(BATCH_SIZE)\n",
    "ds_test_tf = ds_test_tf.prefetch(AUTOTUNE)\n",
    "\n",
    "print(\"TensorFlow data loading completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da777808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PYTORCH DATA LOADING ==========\n",
    "print(\"Loading SVHN dataset with PyTorch...\")\n",
    "\n",
    "# Define transforms untuk preprocessing dan augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load SVHN dataset\n",
    "train_dataset_pt = SVHN(root='./data', split='train', download=True, transform=transform_train)\n",
    "test_dataset_pt = SVHN(root='./data', split='test', download=True, transform=transform_test)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader_pt = DataLoader(train_dataset_pt, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader_pt = DataLoader(test_dataset_pt, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"PyTorch Training samples: {len(train_dataset_pt)}\")\n",
    "print(f\"PyTorch Testing samples: {len(test_dataset_pt)}\")\n",
    "print(\"PyTorch data loading completed!\")\n",
    "\n",
    "# Visualisasi beberapa sample data\n",
    "def visualize_samples():\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "    \n",
    "    # TensorFlow samples\n",
    "    for images, labels in ds_test_tf.take(1):\n",
    "        for i in range(5):\n",
    "            img = images[i].numpy()\n",
    "            # Denormalize untuk visualisasi\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img = img * std + mean\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            axes[0, i].imshow(img)\n",
    "            axes[0, i].set_title(f'TF Label: {labels[i].numpy()}')\n",
    "            axes[0, i].axis('off')\n",
    "    \n",
    "    # PyTorch samples\n",
    "    test_iter = iter(test_loader_pt)\n",
    "    images, labels = next(test_iter)\n",
    "    for i in range(5):\n",
    "        img = images[i].numpy().transpose(1, 2, 0)\n",
    "        # Denormalize untuk visualisasi\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = img * std + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title(f'PT Label: {labels[i].item()}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    axes[0, 0].set_ylabel('TensorFlow', fontsize=14)\n",
    "    axes[1, 0].set_ylabel('PyTorch', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
